{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neo4j queries using Cypher"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We go on by listing our queries and their solutions one by one, for convenience. For that, we are using py2neo to fulfil our Cypher queries in Python.\n",
    "Firstly,you will have to connect through Python to Neo4j, as you did previously, so you can very easily add your credentials as prompted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import py2neo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "graph = py2neo.Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"neo4j_auth\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-05T18:38:02.150290Z",
     "end_time": "2023-04-05T18:38:02.663408Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the total number of retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of retweets is: 24252\n"
     ]
    }
   ],
   "source": [
    "query1 = \"MATCH p=()-[r:RETWEETED]->() RETURN COUNT(*)\"\n",
    "retweets = graph.run(query1).evaluate()\n",
    "print(\"The total number of retweets is:\", retweets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the 20 most popular hashtags (case insensitive) in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 most popular hashtags in descending order are:\n",
      "      popular_hashtags  frequency\n",
      "0          womenintech       4506\n",
      "1     womenempowerment       3736\n",
      "2       genderequality       3205\n",
      "3        100daysofcode       1018\n",
      "4         womenwhocode        990\n",
      "5                women        931\n",
      "6                   ai        877\n",
      "7               coding        855\n",
      "8             violence        815\n",
      "9          datascience        745\n",
      "10         womeninstem        717\n",
      "11              python        690\n",
      "12      womeninscience        689\n",
      "13                tech        684\n",
      "14         programming        611\n",
      "15          javascript        562\n",
      "16  womenentrepreneurs        523\n",
      "17             bigdata        518\n",
      "18          technology        503\n",
      "19    blacktechtwitter        477\n"
     ]
    }
   ],
   "source": [
    "query2 = \"\"\"\n",
    "    MATCH p=()-[r:HAS_HASHTAG]->(n:Hashtag)\n",
    "    RETURN n.tag AS popular_hashtags, COUNT(*) AS frequency\n",
    "    ORDER BY frequency DESC\n",
    "    LIMIT 20\n",
    "\"\"\"\n",
    "pop_hashtags = graph.run(query2).to_data_frame()\n",
    "print('The 20 most popular hashtags in descending order are:')\n",
    "print(pop_hashtags)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the total number of URLs (unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of urls is: 9136\n"
     ]
    }
   ],
   "source": [
    "query3 = \"MATCH (n:URL) RETURN COUNT(n)\"\n",
    "urls = graph.run(query3).evaluate()\n",
    "print(\"The total number of urls is:\", urls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the 20 users with most followers in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 users with most followers in descending order are:\n",
      "           username  followers\n",
      "0          elonmusk  128282742\n",
      "1      narendramodi   86387842\n",
      "2               CNN   61110504\n",
      "3        MileyCyrus   46930879\n",
      "4             POTUS   29400524\n",
      "5           FoxNews   23704890\n",
      "6            Forbes   18710133\n",
      "7               ICC   18401325\n",
      "8              ndtv   17700505\n",
      "9                UN   16213190\n",
      "10      smritiirani   12724316\n",
      "11  harbhajan_singh   11848884\n",
      "12      PiyushGoyal   11685985\n",
      "13         TimesNow   10325121\n",
      "14          binance   10164724\n",
      "15     TheDailyShow    9499257\n",
      "16              ANI    7554914\n",
      "17           snooki    5943793\n",
      "18       Mike_Pence    5823821\n",
      "19        Cobratate    4996182\n"
     ]
    }
   ],
   "source": [
    "query4 = \"\"\"\n",
    "    MATCH (n:User)\n",
    "    WHERE n.followers IS NOT NULL\n",
    "    RETURN n.username AS username, n.followers as followers\n",
    "    ORDER BY followers DESC\n",
    "    LIMIT 20\n",
    "\"\"\"\n",
    "pop_users = graph.run(query4).to_data_frame()\n",
    "print('The 20 users with most followers in descending order are:')\n",
    "print(pop_users)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the hour with the most tweets and retweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  hour with the most tweets and retweets is the 15 th\n"
     ]
    }
   ],
   "source": [
    "query5 = \"\"\"\n",
    "    MATCH (u:User)-[:TWEETED]->(t:Tweet)\n",
    "    WITH u, t, substring(t.created_at, 11, 2) AS hour\n",
    "    RETURN u, t, toInteger(hour) AS tweet_hour\n",
    "    UNION\n",
    "    MATCH (u:User)-[:RETWEETED]->(t:Tweet)\n",
    "    WITH u, t, substring(t.created_at, 11, 2) AS hour\n",
    "    RETURN u, t, toInteger(hour) AS tweet_hour\n",
    "\"\"\"\n",
    "tweet_hour_df = graph.run(query5).to_data_frame()\n",
    "hour_count = tweet_hour_df.groupby(['tweet_hour']).count()['u'].values\n",
    "ind = np.argmax(hour_count)\n",
    "print('The  hour with the most tweets and retweets is the', ind, 'th')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the 20 users, in descending order, that have been mentioned the most\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 users, in descending order, that have been mentioned the most are:\n",
      "           username  number_of_mentions\n",
      "0         Microsoft                6132\n",
      "1     anthonyjdella                6124\n",
      "2      Equal_Fights                 988\n",
      "3        FightHaven                 745\n",
      "4        see_fullen                 737\n",
      "5      GirlsWhoCode                 423\n",
      "6      ToofaniBaba1                 307\n",
      "7         NCMIndiaa                 246\n",
      "8    Khulood_Almani                 233\n",
      "9   NorthernComd_IA                 197\n",
      "10  WomensVoicesNow                 177\n",
      "11   HarishKhuranna                 157\n",
      "12        BJP4Delhi                 157\n",
      "13  Virend_Sachdeva                 157\n",
      "14  jindadilkashmir                 156\n",
      "15   sanjeevchadha8                 156\n",
      "16        TMGAwards                 132\n",
      "17         UN_Women                 125\n",
      "18    PointerSchool                 122\n",
      "19     emily_gunton                 121\n"
     ]
    }
   ],
   "source": [
    "query6 = \"\"\"\n",
    "    MATCH p=()-[r:MENTIONED]->(n:User)\n",
    "    RETURN n.username AS username, COUNT(*) AS number_of_mentions\n",
    "    ORDER BY number_of_mentions DESC\n",
    "    LIMIT 20\n",
    "\"\"\"\n",
    "most_mentioned_users = graph.run(query6).to_data_frame()\n",
    "print('The 20 users, in descending order, that have been mentioned the most are:')\n",
    "print(most_mentioned_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the top 20 tweets that have been retweeted the most and the persons that posted them\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 tweets that have been retweeted the most and the persons that posted them are:\n",
      "               tweet_id            author_id  retweets\n",
      "0   1617735335408017410  1162333473966891008     23351\n",
      "1   1617723820604854272  1499144181822136320     23351\n",
      "2   1614904562577715202   736244975944400896     21311\n",
      "3   1616739692153802753  1578001920169750533     21311\n",
      "4   1615338234250407936  1477971375100887042     21311\n",
      "5   1615254039788400642  1571833730783940609     21311\n",
      "6   1617351171341180928           3271065654     21311\n",
      "7   1616741044154175491  1120982776843399169     21311\n",
      "8   1616748922441199621  1488570069689204736     21311\n",
      "9   1616812458999681025           3093825314     21311\n",
      "10  1615752926869192711  1542755697087102976     21311\n",
      "11  1617535902116642818  1061286182313635842     21311\n",
      "12  1617895018127314944  1587502588957806599     21311\n",
      "13  1615988984060207110  1605845393081712640     21311\n",
      "14  1614904554247815170   736244975944400896     11731\n",
      "15  1617351148654178305           3271065654     11731\n",
      "16  1615254025657815041  1571833730783940609     11731\n",
      "17  1617351191033413634           3271065654     11574\n",
      "18  1617750374051622913   720112912212340736     11574\n",
      "19  1615254048357388288  1571833730783940609     11574\n"
     ]
    }
   ],
   "source": [
    "query7 = \"\"\"\n",
    "    MATCH (n:Tweet)\n",
    "    RETURN n.id as tweet_id, n.author as author_id, n.retweets as retweets\n",
    "    ORDER BY retweets DESC\n",
    "    LIMIT 20\n",
    "\"\"\"\n",
    "most_retweeted = graph.run(query7).to_data_frame()\n",
    "print('The top 20 tweets that have been retweeted the most and the persons that posted them are:')\n",
    "print(most_retweeted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PageRank on the mention network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 highest PageRank scores for the 'Mentioned' network are:         username        score\n",
      "0      Microsoft  1350.284733\n",
      "1  anthonyjdella  1348.455038\n",
      "2   Equal_Fights   435.071162\n",
      "3     FightHaven   165.819832\n",
      "4     see_fullen   163.434105\n",
      "5   ToofaniBaba1   126.009123\n",
      "6   GirlsWhoCode   108.295472\n",
      "7       _EllaBot   108.164522\n",
      "8   PythonRoboto    95.285458\n",
      "9      NCMIndiaa    86.950705\n",
      "The most important user according to the highest PageRank value is: Microsoft\n"
     ]
    }
   ],
   "source": [
    "query8_1 = \"\"\"\n",
    "CALL gds.graph.project.cypher(\n",
    "    'mentionGraph',\n",
    "    'MATCH (u:User) RETURN id(u) AS id',\n",
    "    'MATCH (u:User)-[r:MENTIONED]-(u1:User) RETURN id(u) AS source, id(u1) AS target')\n",
    "\"\"\"\n",
    "query8_2 = \"\"\"\n",
    "    CALL gds.pageRank.stream('mentionGraph') \n",
    "    YIELD nodeId, score\n",
    "    RETURN gds.util.asNode(nodeId).username AS username, score\n",
    "    ORDER BY score DESC LIMIT 10\"\"\"\n",
    "\n",
    "mention_graph = graph.run(query8_1)\n",
    "PR = graph.run(query8_2).to_data_frame()\n",
    "print(\"The 10 highest PageRank scores for the 'Mentioned' network are:\", PR)\n",
    "print(\"The most important user according to the highest PageRank value is:\",\n",
    "      PR.iloc[0].values[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the 20 users with most similar hashtags to the 6th important user(as the others used no hashtags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Τhe 20 users who used most similar hashtags to the 6th important user are: ('sanyaolu', 'saviour_era', 'serenity0312_', 'shiva649531', 'skverma_110', 'talokbhansingh', 'team668866', 'unearthing_29', 'utterlypositive', 'vickypandey1571', 'vikramsaini32', 'vskumarcs', 'yamane_patricia', 'Arbazkhan98786', 'Prvesh17833226', 'Sajeed63814075', 'elisa_kiswa', 'abdulazizbhat83', 'meherabid86', 'quamahbeer91')\n"
     ]
    }
   ],
   "source": [
    "def jaccard_sim(list1, list2):\n",
    "    '''compute Jaccard similarity of two sets'''\n",
    "    intersec = len(set(list1).intersection(set(list2)))\n",
    "    union = len(set(list1).union(set(list2)))\n",
    "    if union > 0:\n",
    "        return intersec / union\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_hashtags(name):\n",
    "    '''get the hashtags used by 6th important user\n",
    "    '''\n",
    "\n",
    "    query = \"\"\"\n",
    "        MATCH (u:User)-[r:USED_HASHTAG]->(h:Hashtag)\n",
    "        WHERE u.username = $name\n",
    "        RETURN DISTINCT h.tag \n",
    "    \"\"\"\n",
    "    tags = graph.run(query, name=name)\n",
    "    hashtags = [t[\"h.tag\"] for t in tags]\n",
    "\n",
    "    return hashtags\n",
    "\n",
    "def get_most_similar_user(name):\n",
    "    '''get the 20 users with most similar hashtags\n",
    "    to the 6th important user'''\n",
    "\n",
    "    user_tags = get_hashtags(name)\n",
    "    query9 = '''MATCH (u:User)-[r:USED_HASHTAG]->(h:Hashtag)\n",
    "        WHERE u.username <> $name\n",
    "        RETURN u.username, COLLECT(h.tag) AS hashtags'''\n",
    "    result = graph.run(query9, name=name)\n",
    "    tag_sim, users = list(), list()\n",
    "    for r in result:\n",
    "        other_user = r[\"u.username\"]\n",
    "        other_tags = r[\"hashtags\"]\n",
    "        if len(other_tags) > 0:\n",
    "            sim = jaccard_sim(user_tags, other_tags)\n",
    "            tag_sim.append(sim)\n",
    "            users.append(other_user)\n",
    "    tag_sim, users = zip(*sorted(zip(tag_sim, users)))\n",
    "\n",
    "    sim_user = users[-20:]\n",
    "    print('Τhe 20 users who used most similar hashtags to the 6th important user are:', sim_user)\n",
    "\n",
    "get_most_similar_user('ToofaniBaba1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the community that each user belongs to in the MENTION graph according to Louvain algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              username  communityId\n",
      "0      Sukhmanjeetkau2            0\n",
      "1      LauraDoodlesToo          825\n",
      "2      AnastasiaNFTart          825\n",
      "3      esquivel_gifted         1333\n",
      "4         DevonGarritt         1333\n",
      "...                ...          ...\n",
      "25630  OscarLegariaMMA          597\n",
      "25631           Ca1d3_          597\n",
      "25632       Irit_Kogan          597\n",
      "25633   HassanMizukage          597\n",
      "25634   Suuuuuuuuuuuux         3984\n",
      "\n",
      "[25635 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "query10 = \"\"\"\n",
    "    CALL gds.louvain.stream('mentionGraph') \n",
    "    YIELD  nodeId, communityId\n",
    "    RETURN gds.util.asNode(nodeId).username AS username, communityId\"\"\"\n",
    "communities = graph.run(query10).to_data_frame()\n",
    "print(communities)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the top 10 most active users along with the number of posts they have made.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 most active users along with the number of posts they have made:\n",
      "        username  number_of_posts\n",
      "0  bcsn_official              262\n",
      "1       CourseOp              116\n",
      "2  Lemetellusthg               96\n",
      "3   Global1Event               79\n",
      "4   Financedata1               78\n",
      "5   Mahsamoulavi               78\n",
      "6       DipsLab3               57\n",
      "7  TrueMisnomers               57\n",
      "8        WeSabio               55\n",
      "9   KerenaNicole               54\n"
     ]
    }
   ],
   "source": [
    "query11 = \"\"\"\n",
    "    MATCH (u:User)-[:TWEETED]->(t:Tweet)\n",
    "    WITH u, COUNT(t) AS number_of_posts\n",
    "    RETURN u.username AS username, number_of_posts\n",
    "    ORDER BY number_of_posts DESC\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "active_users = graph.run(query11).to_data_frame()\n",
    "print('The top 10 most active users along with the number of posts they have made:')\n",
    "print(active_users)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the volumes of each type of tweets (where None is a tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The volumes of each type of tweets are:\n",
      "         type  volume\n",
      "0   retweeted   24252\n",
      "1        None    7133\n",
      "2      quoted     743\n",
      "3  replied_to     954\n"
     ]
    }
   ],
   "source": [
    "query12 = \"\"\"\n",
    "    MATCH (t:Tweet)\n",
    "    RETURN t.type AS type, COUNT(t) AS volume\n",
    "\"\"\"\n",
    "types = graph.run(query12).to_data_frame()\n",
    "print('The volumes of each type of tweets are:')\n",
    "print(types)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
